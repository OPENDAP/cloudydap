{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloudydap Cost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import *\n",
    "from aws_price_list import AWSOffersIndex\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cloudydap_cost(ec2, s3,\n",
    "                   ec2_sku='47GP959QAF69YPG5',\n",
    "                   num_hyrax=1,\n",
    "                   ec2_storage_sku='HY3BZPP2B6K8MSJF',\n",
    "                   ec2_storage_backup='7U7TWP44UP36AT3R',\n",
    "                   ec2_storage_size=5,\n",
    "                   s3_sku='WP9ANXZGBYYSGJEA',\n",
    "                   data_size=115,\n",
    "                   arch3_data_reduction=30,\n",
    "                   dmrpp_size=.27970830719321672100,\n",
    "                   num_files=365,\n",
    "                   num_dsets=777,\n",
    "                   max_bstreams=8,\n",
    "                   egress_data_size=16.63597430725,\n",
    "                   egress_sku='HQEH3ZWJVT46JHRG',\n",
    "                   s3_req_sku='ZWQ6Q48CRJXX4FXE',\n",
    "                   num_dap_data_reqs={'max': 63712, 'min': 0},\n",
    "                   num_dap_meta_reqs={'max': 9286, 'min': 0},\n",
    "                   time_interval='day'):\n",
    "    \"\"\"Compute estimate of Cloudydap AWS costs.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        ec2: Instance of the class representing AWS EC2 price data.\n",
    "\n",
    "        s3: Instance of the class representing AWS S3 price data.\n",
    "\n",
    "        ec2_sku: EC2 instance price as AWS product SKU\n",
    "\n",
    "        num_hyrax: Number of Hyrax servers (assuming one Hyrax server per EC2\n",
    "            instance)\n",
    "\n",
    "        ec2_storage_sku: File system for Hyrax server(s) price AWS product SKU\n",
    "\n",
    "        ec2_storage_backup: File system's backup price as AWS product SKU\n",
    "\n",
    "        ec2_storage_size: File system size in gigabytes (GB)\n",
    "\n",
    "        s3_sku: S3 storage price as AWS product SKU\n",
    "\n",
    "        data_size: Data collection's size in gigabytes (GB)\n",
    "\n",
    "        arch3_data_reduction: Saving as percentage in data storage from file\n",
    "            shredding\n",
    "\n",
    "        dmrpp_size: Size of DMR++ (index) files as percentage of the data\n",
    "            collection's size.\n",
    "\n",
    "        num_files: Number of files in the data collection.\n",
    "\n",
    "        num_dsets: Number of datasets (variables) per file.\n",
    "\n",
    "        max_bstreams: Maximum number of byte streams per dataset.\n",
    "\n",
    "        egress_data_size: Daily amount of egress data in gigabytes (GB).\n",
    "\n",
    "        egress_sku: Data egress price as AWS product SKU.\n",
    "\n",
    "        s3_req_sku: S3 requests price as AWS product SKU.\n",
    "\n",
    "        num_dap_data_reqs: Min/max number of DAP data requests per day.\n",
    "\n",
    "        num_dap_meta_reqs: Min/max number of DAP metadata requests per day.\n",
    "\n",
    "        time_unit: Time interval of cost data. Can be: monthly, daily, hourly.\n",
    "    \"\"\"\n",
    "    # Helper function to check price units...\n",
    "    def _check_units(units, expected):\n",
    "        if units != expected:\n",
    "            raise ValueError('Units mismatch: \"%s\", expected \"%s\"'\n",
    "                             % (units, expected))\n",
    "\n",
    "    # Cost data will be stored in a pandas' DataFrame, using the same column\n",
    "    # names as those in the Detailed Hourly AWS Cost and Usage Reports.\n",
    "    cost = pd.DataFrame(columns=['Arch', 'lineItem/ProductCode',\n",
    "                                 'lineItem/UsageType', 'lineItem/Operation',\n",
    "                                 'lineItem/BlendedCost'])\n",
    "\n",
    "    # ## Cost Calculation\n",
    "\n",
    "    # The costs will be calculated based on the specified time interval. It can\n",
    "    # be monthly, daily, or hourly.\n",
    "    days_in_month = 30\n",
    "    if time_interval == 'month':\n",
    "        time_unit = 1\n",
    "    elif time_interval == 'day':\n",
    "        time_unit = days_in_month\n",
    "    elif time_interval == 'hour':\n",
    "        time_unit = days_in_month * 24\n",
    "    else:\n",
    "        raise ValueError('%s: Invalid time interval' % time_interval)\n",
    "\n",
    "    # ### EC2 Cost\n",
    "    x = ec2.product(ec2_sku).pricing[0]\n",
    "    _check_units(x.price_unit, 'Hrs')\n",
    "    x = num_hyrax * x.get_price((days_in_month * 24) / time_unit)\n",
    "    cost.loc[len(cost)] = pd.Series({'Arch': 'A1',\n",
    "                                     'lineItem/ProductCode': 'AmazonEC2',\n",
    "                                     'lineItem/UsageType': 'BoxUsage',\n",
    "                                     'lineItem/Operation': 'RunInstances',\n",
    "                                     'lineItem/BlendedCost': x})\n",
    "    cost.loc[len(cost)] = pd.Series({'Arch': 'A2',\n",
    "                                     'lineItem/ProductCode': 'AmazonEC2',\n",
    "                                     'lineItem/UsageType': 'BoxUsage',\n",
    "                                     'lineItem/Operation': 'RunInstances',\n",
    "                                     'lineItem/BlendedCost': x})\n",
    "    cost.loc[len(cost)] = pd.Series({'Arch': 'A3',\n",
    "                                     'lineItem/ProductCode': 'AmazonEC2',\n",
    "                                     'lineItem/UsageType': 'BoxUsage',\n",
    "                                     'lineItem/Operation': 'RunInstances',\n",
    "                                     'lineItem/BlendedCost': x})\n",
    "\n",
    "    # ### EC2 Local Storage Cost for A1\n",
    "    x = ec2.product(ec2_storage_sku).pricing[0]\n",
    "    _check_units(x.price_unit, 'GB-Mo')\n",
    "    x = x.get_price(ec2_storage_size) / time_unit\n",
    "    cost.loc[len(cost)] = pd.Series({'Arch': 'A1',\n",
    "                                     'lineItem/ProductCode': 'AmazonEC2',\n",
    "                                     'lineItem/UsageType': 'EBS:VolumeUsage',\n",
    "                                     'lineItem/Operation': 'CreateVolume',\n",
    "                                     'lineItem/BlendedCost': x})\n",
    "\n",
    "    x = ec2.product(ec2_storage_backup).pricing[0]\n",
    "    _check_units(x.price_unit, 'GB-Mo')\n",
    "    x = x.get_price(ec2_storage_size) / time_unit\n",
    "    cost.loc[len(cost)] = pd.Series({'Arch': 'A1',\n",
    "                                     'lineItem/ProductCode': 'AmazonEC2',\n",
    "                                     'lineItem/UsageType': 'EBS:SnapshotUsage',\n",
    "                                     'lineItem/Operation': 'CreateSnapshot',\n",
    "                                     'lineItem/BlendedCost': x})\n",
    "\n",
    "    # ### S3 Storage Cost\n",
    "    s3_storage_pricing = s3.product(s3_sku).pricing[0]\n",
    "    _check_units(s3_storage_pricing.price_unit, 'GB-Mo')\n",
    "\n",
    "    # For Architecture \\#1:\n",
    "    x = s3_storage_pricing.get_price(data_size) / time_unit\n",
    "    cost.loc[len(cost)] = pd.Series({'Arch': 'A1',\n",
    "                                     'lineItem/ProductCode': 'AmazonS3',\n",
    "                                     'lineItem/UsageType': 'TimedStorage',\n",
    "                                     'lineItem/Operation': 'StandardStorage',\n",
    "                                     'lineItem/BlendedCost': x})\n",
    "\n",
    "    # For Architecture \\#2: data collection plus the DMR++ (index) files.\n",
    "    x = s3_storage_pricing.get_price(\n",
    "        data_size * (1 + dmrpp_size/100)) / time_unit\n",
    "    cost.loc[len(cost)] = pd.Series({'Arch': 'A2',\n",
    "                                     'lineItem/ProductCode': 'AmazonS3',\n",
    "                                     'lineItem/UsageType': 'TimedStorage',\n",
    "                                     'lineItem/Operation': 'StandardStorage',\n",
    "                                     'lineItem/BlendedCost': x})\n",
    "\n",
    "    # For Architecture \\#3: data collection minus the reduction from duplicate\n",
    "    # byte streams plus the DMR++ (index) files.\n",
    "    x = s3_storage_pricing.get_price(\n",
    "        data_size * (1 + (dmrpp_size - arch3_data_reduction)/100)) / time_unit\n",
    "    cost.loc[len(cost)] = pd.Series({'Arch': 'A3',\n",
    "                                     'lineItem/ProductCode': 'AmazonS3',\n",
    "                                     'lineItem/UsageType': 'TimedStorage',\n",
    "                                     'lineItem/Operation': 'StandardStorage',\n",
    "                                     'lineItem/BlendedCost': x})\n",
    "\n",
    "    # ### Egress Data\n",
    "    x = ec2.product(egress_sku).pricing[0]\n",
    "    _check_units(x.price_unit, 'GB')\n",
    "    x = x.get_price(egress_data_size * (days_in_month / time_unit))\n",
    "    for arch in ['A1', 'A2', 'A3']:\n",
    "        cost.loc[len(cost)] = pd.Series(\n",
    "            {'Arch': arch,\n",
    "             'lineItem/ProductCode': 'AmazonEC2',\n",
    "             'lineItem/UsageType': 'DataTransfer-Out-Bytes',\n",
    "             'lineItem/Operation': 'RunInstances',\n",
    "             'lineItem/BlendedCost': x})\n",
    "\n",
    "    # ### DAP Requests\n",
    "    #\n",
    "    # This part is about modelling the cost of S3 requests. There are two types\n",
    "    # of DAP requests: data and metadata. For metadata requests, we will assume\n",
    "    # only one S3 request to retrieve the DMR++ (index) file. For data DAP\n",
    "    # requests, one S3 request for Architecture \\#1 and either 1 or\n",
    "    # `max_bstreams` for Architecture \\#2 and \\#3.\n",
    "    s3_reqs = s3.product(s3_req_sku).pricing[0]\n",
    "    _check_units(s3_reqs.price_unit, 'Requests')\n",
    "\n",
    "    # DAP metadata and data requests translated into S3 requests:\n",
    "    for arch in ['A1', 'A2', 'A3']:\n",
    "        for cat in ['min', 'max']:\n",
    "            # S3 requests cost from DAP metadata requests...\n",
    "            meta_cost = s3_reqs.get_price(\n",
    "                num_dap_meta_reqs[cat] * 1 * (days_in_month / time_unit))\n",
    "\n",
    "            # S3 requests cost from DAP data requests...\n",
    "            if arch == 'A1':\n",
    "                data_cost = s3_reqs.get_price(\n",
    "                    num_dap_data_reqs[cat] * 1 * (days_in_month / time_unit))\n",
    "                cost.loc[len(cost)] = pd.Series(\n",
    "                    {'Arch': arch, 'lineItem/ProductCode': 'AmazonS3',\n",
    "                     'lineItem/UsageType': 'Requests-Tier2',\n",
    "                     'lineItem/Operation': 'GetObject',\n",
    "                     'lineItem/BlendedCost': meta_cost + data_cost})\n",
    "            else:\n",
    "                for n in [1, max_bstreams]:\n",
    "                    data_cost = s3_reqs.get_price(\n",
    "                        num_dap_data_reqs[cat] * n * (days_in_month / time_unit))\n",
    "                    cost.loc[len(cost)] = pd.Series(\n",
    "                        {'Arch': arch, 'lineItem/ProductCode': 'AmazonS3',\n",
    "                         'lineItem/UsageType': 'Requests-Tier2',\n",
    "                         'lineItem/Operation': 'GetObject',\n",
    "                         'lineItem/BlendedCost': meta_cost + data_cost})\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost data will be stored in a pandas' DataFrame, using the same column names as those in the Detailed Hourly AWS Cost and Usage Reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = pd.DataFrame(columns=['Scenario', 'Arch', 'lineItem/ProductCode', \n",
    "                             'lineItem/UsageType', 'lineItem/Operation', \n",
    "                             'lineItem/BlendedCost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Price Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Offer Index File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oi = AWSOffersIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Mar  3 00:26:06 2017 UTC+00:00'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oi.published.strftime('%c %Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat Mar 11 02:04:33 2017 UTC+00:00'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oi.accessed.strftime('%c %Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon EC2 Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec2 = oi.offer('AmazonEC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu Mar  2 18:32:21 2017 UTC+00:00'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec2.published.strftime('%c %Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat Mar 11 02:04:46 2017 UTC+00:00'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec2.accessed.strftime('%c %Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon S3 Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s3 = oi.offer('AmazonS3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Jan 27 22:16:42 2017 UTC+00:00'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.published.strftime('%c %Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat Mar 11 02:04:47 2017 UTC+00:00'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.accessed.strftime('%c %Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cost Computation Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Arch</th>\n",
       "      <th>lineItem/ProductCode</th>\n",
       "      <th>lineItem/UsageType</th>\n",
       "      <th>lineItem/Operation</th>\n",
       "      <th>lineItem/BlendedCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Scenario, Arch, lineItem/ProductCode, lineItem/UsageType, lineItem/Operation, lineItem/BlendedCost]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ec2_sku = Text(value='47GP959QAF69YPG5', disabled=True)\n",
    "ec2_storage_sku = Text(value='HY3BZPP2B6K8MSJF', disabled=True)\n",
    "ec2_storage_backup = Text(value='7U7TWP44UP36AT3R', disabled=True)\n",
    "s3_sku = Text(value='WP9ANXZGBYYSGJEA', disabled=True)\n",
    "egress_sku = Text(value='HQEH3ZWJVT46JHRG', disabled=True)\n",
    "s3_req_sku = Text(value='ZWQ6Q48CRJXX4FXE', disabled=True)\n",
    "\n",
    "vb1 = VBox([\n",
    "    HBox([Label('EC2 instance price as AWS product SKU'), ec2_sku]),\n",
    "    HBox([Label('EC2 file system price as AWS product SKU'), \n",
    "        ec2_storage_sku]),\n",
    "    HBox([Label('EC2 file system backup price as AWS product SKU'), \n",
    "        ec2_storage_backup]),\n",
    "    HBox([Label('S3 storage price as AWS product SKU'), s3_sku]),\n",
    "    HBox([Label('Data egress price as AWS product SKU'), egress_sku]),\n",
    "    HBox([Label('S3 requests price as AWS product SKU'), s3_req_sku])], \n",
    "    layout=Layout(border='solid'))\n",
    "\n",
    "num_hyrax = IntText(value=1, disabled=False)\n",
    "ec2_storage_size = FloatText(value=5, disabled=False)\n",
    "data_size = FloatText(value=16448.6, disabled=False)\n",
    "arch3_data_reduction = FloatText(value=30, disabled=False)\n",
    "dmrpp_size = FloatText(value=.27970830719321672100, disabled=False)\n",
    "num_files = IntText(value=365, disabled=False)\n",
    "num_dsets = IntText(value=777, disabled=False)\n",
    "max_bstreams = IntText(value=8, disabled=False)\n",
    "egress_data_size = FloatText(value=16.63597430725, disabled=False)\n",
    "num_dap_data_reqs_max = IntText(value=63712, description= 'max', disabled=False)\n",
    "num_dap_data_reqs_min = IntText(value=0, description='min', disabled=False)\n",
    "num_dap_meta_reqs_max = IntText(value=9286, description='max', disabled=False)\n",
    "num_dap_meta_reqs_min = IntText(value=0, description='min', disabled=False)\n",
    "time_interval = Dropdown(options=['month', 'day', 'hour'], value='day')\n",
    "\n",
    "vb2 = VBox([\n",
    "    HBox([Label('Number of EC2 instances'), num_hyrax]),\n",
    "    HBox([Label('EC2 file system size in gigabytes (GB)'), ec2_storage_size]),\n",
    "    HBox([Label('Data collection size in gigabytes (GB)'), data_size]),\n",
    "    HBox([Label('Number of files in the data collection'), num_files]),\n",
    "    HBox([Label('Number of datasets (variables) per file'), num_dsets]),\n",
    "    HBox([Label('Maximum number of byte streams per dataset'), max_bstreams]),\n",
    "    HBox([Label('Reduction as percentage in data storage from file shredding'), arch3_data_reduction]),\n",
    "    HBox([Label('Size of DMR++ (index) files as percentage of the data collection size'), dmrpp_size]),\n",
    "    HBox([Label('Daily amount of egress data in gigabytes (GB)'), egress_data_size]),\n",
    "    HBox([Label('Number of DAP data requests per day'), num_dap_data_reqs_min, num_dap_data_reqs_max]),\n",
    "    HBox([Label('Number of DAP metadata requests per day'), num_dap_meta_reqs_min, num_dap_meta_reqs_max]),\n",
    "    HBox([Label('Cost period'), time_interval])\n",
    "], layout=Layout(border='solid'))\n",
    "\n",
    "scenario = Text(value='', layout=Layout(width='25%'))\n",
    "run = Button(description='Run cost model', button_style='danger')\n",
    "reset = Button(description='Reset cost data', button_style='info')\n",
    "copy = Button(description='Copy cost data to clipboard', button_style='info')\n",
    "copy.layout.width = '185px'\n",
    "\n",
    "\n",
    "def reset_costs(b):\n",
    "    global cost\n",
    "\n",
    "    clear_output()\n",
    "    cost.drop(cost.index, inplace=True)\n",
    "    display(cost)\n",
    "\n",
    "    \n",
    "def run_model(b):\n",
    "    global cost\n",
    "\n",
    "    clear_output()\n",
    "    if not scenario.value:\n",
    "        raise ValueError('Please set the cost scenario.')\n",
    "    else:\n",
    "        if (cost.Scenario == scenario.value).any():\n",
    "            raise ValueError('%s: Scenario name alredy used' % scenario.value)\n",
    "\n",
    "    num_dap_data_reqs = {'max': num_dap_data_reqs_max.value,\n",
    "                         'min': num_dap_data_reqs_min.value}\n",
    "    num_dap_meta_reqs = {'max': num_dap_meta_reqs_max.value,\n",
    "                         'min': num_dap_meta_reqs_min.value}\n",
    "    this_cost = cloudydap_cost(\n",
    "        ec2, \n",
    "        s3,\n",
    "        num_hyrax=num_hyrax.value,\n",
    "        ec2_storage_size=ec2_storage_size.value,\n",
    "        data_size=data_size.value,\n",
    "        arch3_data_reduction=arch3_data_reduction.value,\n",
    "        dmrpp_size=dmrpp_size.value,\n",
    "        num_files=num_files.value,\n",
    "        num_dsets=num_dsets.value,\n",
    "        max_bstreams=max_bstreams.value,\n",
    "        egress_data_size=egress_data_size.value,\n",
    "        num_dap_data_reqs=num_dap_data_reqs,\n",
    "        num_dap_meta_reqs=num_dap_meta_reqs,\n",
    "        time_interval=time_interval.value)\n",
    "    this_cost['Scenario'] = scenario.value\n",
    "    scenario.value = ''\n",
    "\n",
    "    cost = cost.append(this_cost, ignore_index=True)[cost.columns.tolist()]\n",
    "    display(cost)\n",
    "\n",
    "    \n",
    "def copy_clip(b):\n",
    "    global cost\n",
    "\n",
    "    cost.to_clipboard(index=False)\n",
    "\n",
    "\n",
    "run.on_click(run_model)\n",
    "reset.on_click(reset_costs)\n",
    "copy.on_click(copy_clip)\n",
    "\n",
    "t = Tab([vb2, vb1])\n",
    "t.set_title(0, 'Cost Model Parameters')\n",
    "t.set_title(1, 'AWS Price Information')\n",
    "\n",
    "VBox([t, HBox([Label('Cost scenario'), scenario, run, reset, copy])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {
    "16b92ef862134a9dbb294bce733db3d2": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
